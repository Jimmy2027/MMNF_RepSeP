@article{sutter_learning_nodate,
    title = {Learning from multiple data types utilizing abstract mean functions},
    pages = {4},
    author = {Sutter, Thonas M},
    langid = {english},
    file = {Sutter - Learning from multiple data types utilizing abstra.pdf:/Users/Hendrik/Zotero/storage/M2B8W74M/Sutter - Learning from multiple data types utilizing abstra.pdf:application/pdf}
}

@article{rezende_variational_2016,
    title = {Variational Inference with Normalizing Flows},
    url = {http://arxiv.org/abs/1505.05770},
    abstract = {The choice of approximate posterior distribution is one of the core problems in variational inference. Most applications of variational inference employ simple families of posterior approximations in order to allow for efficient inference, focusing on mean-field or other simple structured approximations. This restriction has a significant impact on the quality of inferences made using variational methods. We introduce a new approach for specifying flexible, arbitrarily complex and scalable approximate posterior distributions. Our approximations are distributions constructed through a normalizing flow, whereby a simple initial density is transformed into a more complex one by applying a sequence of invertible transformations until a desired level of complexity is attained. We use this view of normalizing flows to develop categories of finite and infinitesimal flows and provide a unified view of approaches for constructing rich posterior approximations. We demonstrate that the theoretical advantages of having posteriors that better match the true posterior, combined with the scalability of amortized variational approaches, provides a clear improvement in performance and applicability of variational inference.},
    journaltitle = {{arXiv}:1505.05770 [cs, stat]},
    author = {Rezende, Danilo Jimenez and Mohamed, Shakir},
    urldate = {2021-03-22},
    date = {2016-06-14},
    eprinttype = {arxiv},
    eprint = {1505.05770},
    keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Statistics - Computation, Statistics - Machine Learning, Statistics - Methodology},
    file = {arXiv Fulltext PDF:/Users/Hendrik/Zotero/storage/EFPQNS97/Rezende and Mohamed - 2016 - Variational Inference with Normalizing Flows.pdf:application/pdf;arXiv.org Snapshot:/Users/Hendrik/Zotero/storage/VSGUU2S3/1505.html:text/html}
}

@article{kingma_improving_2017,
    title = {Improving Variational Inference with Inverse Autoregressive Flow},
    url = {http://arxiv.org/abs/1606.04934},
    abstract = {The framework of normalizing flows provides a general strategy for flexible variational inference of posteriors over latent variables. We propose a new type of normalizing flow, inverse autoregressive flow ({IAF}), that, in contrast to earlier published flows, scales well to high-dimensional latent spaces. The proposed flow consists of a chain of invertible transformations, where each transformation is based on an autoregressive neural network. In experiments, we show that {IAF} significantly improves upon diagonal Gaussian approximate posteriors. In addition, we demonstrate that a novel type of variational autoencoder, coupled with {IAF}, is competitive with neural autoregressive models in terms of attained log-likelihood on natural images, while allowing significantly faster synthesis.},
    journaltitle = {{arXiv}:1606.04934 [cs, stat]},
    author = {Kingma, Diederik P. and Salimans, Tim and Jozefowicz, Rafal and Chen, Xi and Sutskever, Ilya and Welling, Max},
    urldate = {2021-03-22},
    date = {2017-01-30},
    eprinttype = {arxiv},
    eprint = {1606.04934},
    keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
    file = {arXiv Fulltext PDF:/Users/Hendrik/Zotero/storage/XL6NVUH7/Kingma et al. - 2017 - Improving Variational Inference with Inverse Autor.pdf:application/pdf;arXiv.org Snapshot:/Users/Hendrik/Zotero/storage/DB4II29Q/1606.html:text/html}
}

@article{kobyzev_normalizing_2020,
    title = {Normalizing Flows: An Introduction and Review of Current Methods},
    issn = {1939-3539},
    doi = {10.1109/TPAMI.2020.2992934},
    shorttitle = {Normalizing Flows},
    abstract = {Normalizing Flows are generative models which produce tractable distributions where both sampling and density evaluation can be efficient and exact. The goal of this survey article is to give a coherent and comprehensive review of the literature around the construction and use of Normalizing Flows for distribution learning. We aim to provide context and explanation of the models, review current state-of-the-art literature, and identify open questions and promising future directions.},
    pages = {1--1},
    journaltitle = {{IEEE} Transactions on Pattern Analysis and Machine Intelligence},
    author = {Kobyzev, I. and Prince, S. and Brubaker, M.},
    date = {2020},
    note = {Conference Name: {IEEE} Transactions on Pattern Analysis and Machine Intelligence},
    keywords = {Computational modeling, Context modeling, Density estimation, Estimation, Generative models, Invertible neural networks, Jacobian matrices, Mathematical model, Normalizing flows, Random variables, Training, Variational inference},
    file = {IEEE Xplore Full Text PDF:/Users/Hendrik/Zotero/storage/7IGXE2K7/Kobyzev et al. - 2020 - Normalizing Flows An Introduction and Review of C.pdf:application/pdf}
}

@article{papamakarios_normalizing_2019,
    title = {Normalizing Flows for Probabilistic Modeling and Inference},
    url = {http://arxiv.org/abs/1912.02762},
    abstract = {Normalizing ﬂows provide a general mechanism for deﬁning expressive probability distributions, only requiring the speciﬁcation of a (usually simple) base distribution and a series of bijective transformations. There has been much recent work on normalizing ﬂows, ranging from improving their expressive power to expanding their application. We believe the ﬁeld has now matured and is in need of a uniﬁed perspective. In this review, we attempt to provide such a perspective by describing ﬂows through the lens of probabilistic modeling and inference. We place special emphasis on the fundamental principles of ﬂow design, and discuss foundational topics such as expressive power and computational trade-oﬀs. We also broaden the conceptual framing of ﬂows by relating them to more general probability transformations. Lastly, we summarize the use of ﬂows for tasks such as generative modeling, approximate inference, and supervised learning.},
    journaltitle = {{arXiv}:1912.02762 [cs, stat]},
    author = {Papamakarios, George and Nalisnick, Eric and Rezende, Danilo Jimenez and Mohamed, Shakir and Lakshminarayanan, Balaji},
    urldate = {2021-03-24},
    date = {2019-12-05},
    langid = {english},
    eprinttype = {arxiv},
    eprint = {1912.02762},
    keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
    file = {Papamakarios et al. - 2019 - Normalizing Flows for Probabilistic Modeling and I.pdf:/Users/Hendrik/Zotero/storage/76PKLB7E/Papamakarios et al. - 2019 - Normalizing Flows for Probabilistic Modeling and I.pdf:application/pdf}
}

@article{baltrusaitis_multimodal_2019,
    title = {Multimodal Machine Learning: A Survey and Taxonomy},
    volume = {41},
    issn = {1939-3539},
    doi = {10.1109/TPAMI.2018.2798607},
    shorttitle = {Multimodal Machine Learning},
    abstract = {Our experience of the world is multimodal - we see objects, hear sounds, feel texture, smell odors, and taste flavors. Modality refers to the way in which something happens or is experienced and a research problem is characterized as multimodal when it includes multiple such modalities. In order for Artificial Intelligence to make progress in understanding the world around us, it needs to be able to interpret such multimodal signals together. Multimodal machine learning aims to build models that can process and relate information from multiple modalities. It is a vibrant multi-disciplinary field of increasing importance and with extraordinary potential. Instead of focusing on specific multimodal applications, this paper surveys the recent advances in multimodal machine learning itself and presents them in a common taxonomy. We go beyond the typical early and late fusion categorization and identify broader challenges that are faced by multimodal machine learning, namely: representation, translation, alignment, fusion, and co-learning. This new taxonomy will enable researchers to better understand the state of the field and identify directions for future research.},
    pages = {423--443},
    number = {2},
    journaltitle = {{IEEE} Transactions on Pattern Analysis and Machine Intelligence},
    author = {Baltrušaitis, T. and Ahuja, C. and Morency, L.},
    date = {2019-02},
    note = {Conference Name: {IEEE} Transactions on Pattern Analysis and Machine Intelligence},
    keywords = {Hidden Markov models, introductory, machine learning, Media, Multimedia communication, Multimodal, Speech, Speech recognition, Streaming media, survey, Visualization},
    file = {IEEE Xplore Abstract Record:/Users/Hendrik/Zotero/storage/GRLQHZ3N/8269806.html:text/html;IEEE Xplore Full Text PDF:/Users/Hendrik/Zotero/storage/9X742YZK/Baltrušaitis et al. - 2019 - Multimodal Machine Learning A Survey and Taxonomy.pdf:application/pdf}
}

@inproceedings{karpathy_deep_2015,
    title = {Deep Visual-Semantic Alignments for Generating Image Descriptions},
    url = {https://www.cv-foundation.org/openaccess/content_cvpr_2015/html/Karpathy_Deep_Visual-Semantic_Alignments_2015_CVPR_paper.html},
    eventtitle = {Proceedings of the {IEEE} Conference on Computer Vision and Pattern Recognition},
    pages = {3128--3137},
    author = {Karpathy, Andrej and Fei-Fei, Li},
    urldate = {2021-03-30},
    date = {2015},
    file = {Full Text PDF:/Users/Hendrik/Zotero/storage/B48CM24P/Karpathy and Fei-Fei - 2015 - Deep Visual-Semantic Alignments for Generating Ima.pdf:application/pdf;Snapshot:/Users/Hendrik/Zotero/storage/JZ7JVFPQ/Karpathy_Deep_Visual-Semantic_Alignments_2015_CVPR_paper.html:text/html}
}

@article{kingma_auto-encoding_2014,
    title = {Auto-Encoding Variational Bayes},
    url = {http://arxiv.org/abs/1312.6114},
    abstract = {How can we perform efficient inference and learning in directed probabilistic models, in the presence of continuous latent variables with intractable posterior distributions, and large datasets? We introduce a stochastic variational inference and learning algorithm that scales to large datasets and, under some mild differentiability conditions, even works in the intractable case. Our contributions is two-fold. First, we show that a reparameterization of the variational lower bound yields a lower bound estimator that can be straightforwardly optimized using standard stochastic gradient methods. Second, we show that for i.i.d. datasets with continuous latent variables per datapoint, posterior inference can be made especially efficient by fitting an approximate inference model (also called a recognition model) to the intractable posterior using the proposed lower bound estimator. Theoretical advantages are reflected in experimental results.},
    journaltitle = {{arXiv}:1312.6114 [cs, stat]},
    author = {Kingma, Diederik P. and Welling, Max},
    urldate = {2021-03-30},
    date = {2014-05-01},
    eprinttype = {arxiv},
    eprint = {1312.6114},
    keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
    file = {arXiv Fulltext PDF:/Users/Hendrik/Zotero/storage/YN7CSDUJ/Kingma and Welling - 2014 - Auto-Encoding Variational Bayes.pdf:application/pdf;arXiv.org Snapshot:/Users/Hendrik/Zotero/storage/QX9BK2YR/1312.html:text/html}
}

@book{niculescu_convex_2018,
    location = {Cham},
    title = {Convex Functions and Their Applications},
    isbn = {978-3-319-78336-9 978-3-319-78337-6},
    url = {http://link.springer.com/10.1007/978-3-319-78337-6},
    series = {{CMS} Books in Mathematics},
    publisher = {Springer International Publishing},
    author = {Niculescu, Constantin P. and Persson, Lars-Erik},
    urldate = {2021-03-30},
    date = {2018},
    langid = {english},
    doi = {10.1007/978-3-319-78337-6},
    file = {Niculescu and Persson - 2018 - Convex Functions and Their Applications.pdf:/Users/Hendrik/Zotero/storage/PWHQL3RY/Niculescu and Persson - 2018 - Convex Functions and Their Applications.pdf:application/pdf}
}


@article{shi_variational_2019,
    title = {Variational Mixture-of-Experts Autoencoders for Multi-Modal Deep Generative Models},
    url = {http://arxiv.org/abs/1911.03393},
    abstract = {Learning generative models that span multiple data modalities, such as vision and language, is often motivated by the desire to learn more useful, generalisable representations that faithfully capture common underlying factors between the modalities. In this work, we characterise successful learning of such models as the fulfillment of four criteria: i) implicit latent decomposition into shared and private subspaces, ii) coherent joint generation over all modalities, iii) coherent cross-generation across individual modalities, and iv) improved model learning for individual modalities through multi-modal integration. Here, we propose a mixture-of-experts multimodal variational autoencoder ({MMVAE}) to learn generative models on different sets of modalities, including a challenging image-language dataset, and demonstrate its ability to satisfy all four criteria, both qualitatively and quantitatively.},
    journaltitle = {{arXiv}:1911.03393 [cs, stat]},
    author = {Shi, Yuge and Siddharth, N. and Paige, Brooks and Torr, Philip H. S.},
    urldate = {2021-03-30},
    date = {2019-11-08},
    eprinttype = {arxiv},
    eprint = {1911.03393},
    keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
    file = {arXiv Fulltext PDF:/Users/Hendrik/Zotero/storage/RCT86RBU/Shi et al. - 2019 - Variational Mixture-of-Experts Autoencoders for Mu.pdf:application/pdf;arXiv.org Snapshot:/Users/Hendrik/Zotero/storage/LB9ZB8L7/1911.html:text/html}
}

@article{sutter_multimodal_2020,
    title = {Multimodal Generative Learning Utilizing Jensen-Shannon-Divergence},
    url = {http://arxiv.org/abs/2006.08242},
    abstract = {Learning from different data types is a long-standing goal in machine learning research, as multiple information sources co-occur when describing natural phenomena. However, existing generative models that approximate a multimodal {ELBO} rely on difficult or inefficient training schemes to learn a joint distribution and the dependencies between modalities. In this work, we propose a novel, efficient objective function that utilizes the Jensen-Shannon divergence for multiple distributions. It simultaneously approximates the unimodal and joint multimodal posteriors directly via a dynamic prior. In addition, we theoretically prove that the new multimodal {JS}-divergence ({mmJSD}) objective optimizes an {ELBO}. In extensive experiments, we demonstrate the advantage of the proposed {mmJSD} model compared to previous work in unsupervised, generative learning tasks.},
    journaltitle = {{arXiv}:2006.08242 [cs, stat]},
    author = {Sutter, Thomas M. and Daunhawer, Imant and Vogt, Julia E.},
    urldate = {2021-03-30},
    date = {2020-11-02},
    eprinttype = {arxiv},
    eprint = {2006.08242},
    keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
    file = {arXiv Fulltext PDF:/Users/Hendrik/Zotero/storage/2SGSPF93/Sutter et al. - 2020 - Multimodal Generative Learning Utilizing Jensen-Sh.pdf:application/pdf;arXiv.org Snapshot:/Users/Hendrik/Zotero/storage/4VI64PCH/2006.html:text/html}
}

@article{suzuki_joint_2016,
    title = {Joint Multimodal Learning with Deep Generative Models},
    url = {http://arxiv.org/abs/1611.01891},
    abstract = {We investigate deep generative models that can exchange multiple modalities bi-directionally, e.g., generating images from corresponding texts and vice versa. Recently, some studies handle multiple modalities on deep generative models, such as variational autoencoders ({VAEs}). However, these models typically assume that modalities are forced to have a conditioned relation, i.e., we can only generate modalities in one direction. To achieve our objective, we should extract a joint representation that captures high-level concepts among all modalities and through which we can exchange them bi-directionally. As described herein, we propose a joint multimodal variational autoencoder ({JMVAE}), in which all modalities are independently conditioned on joint representation. In other words, it models a joint distribution of modalities. Furthermore, to be able to generate missing modalities from the remaining modalities properly, we develop an additional method, {JMVAE}-kl, that is trained by reducing the divergence between {JMVAE}'s encoder and prepared networks of respective modalities. Our experiments show that our proposed method can obtain appropriate joint representation from multiple modalities and that it can generate and reconstruct them more properly than conventional {VAEs}. We further demonstrate that {JMVAE} can generate multiple modalities bi-directionally.},
    journaltitle = {{arXiv}:1611.01891 [cs, stat]},
    author = {Suzuki, Masahiro and Nakayama, Kotaro and Matsuo, Yutaka},
    urldate = {2021-03-30},
    date = {2016-11-06},
    eprinttype = {arxiv},
    eprint = {1611.01891},
    keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
    file = {arXiv Fulltext PDF:/Users/Hendrik/Zotero/storage/UZXUCHRL/Suzuki et al. - 2016 - Joint Multimodal Learning with Deep Generative Mod.pdf:application/pdf;arXiv.org Snapshot:/Users/Hendrik/Zotero/storage/2K9XPIJP/1611.html:text/html}
}

@inproceedings{tsai_learning_2018,
    title = {Learning Factorized Multimodal Representations},
    url = {https://openreview.net/forum?id=rygqqsA9KX},
    abstract = {We propose a model to learn factorized multimodal representations that are discriminative, generative, and interpretable.},
    eventtitle = {International Conference on Learning Representations},
    author = {Tsai, Yao-Hung Hubert and Liang, Paul Pu and Zadeh, Amir and Morency, Louis-Philippe and Salakhutdinov, Ruslan},
    urldate = {2021-03-30},
    date = {2018-09-27},
    langid = {english},
    file = {Full Text PDF:/Users/Hendrik/Zotero/storage/6A6KSPN4/Tsai et al. - 2018 - Learning Factorized Multimodal Representations.pdf:application/pdf;Snapshot:/Users/Hendrik/Zotero/storage/GDQUU3I9/forum.html:text/html}
}

@article{vedantam_generative_2018,
    title = {Generative Models of Visually Grounded Imagination},
    url = {http://arxiv.org/abs/1705.10762},
    abstract = {It is easy for people to imagine what a man with pink hair looks like, even if they have never seen such a person before. We call the ability to create images of novel semantic concepts visually grounded imagination. In this paper, we show how we can modify variational auto-encoders to perform this task. Our method uses a novel training objective, and a novel product-of-experts inference network, which can handle partially specified (abstract) concepts in a principled and efficient way. We also propose a set of easy-to-compute evaluation metrics that capture our intuitive notions of what it means to have good visual imagination, namely correctness, coverage, and compositionality (the 3 C's). Finally, we perform a detailed comparison of our method with two existing joint image-attribute {VAE} methods (the {JMVAE} method of Suzuki et.al. and the {BiVCCA} method of Wang et.al.) by applying them to two datasets: the {MNIST}-with-attributes dataset (which we introduce here), and the {CelebA} dataset.},
    journaltitle = {{arXiv}:1705.10762 [cs, stat]},
    author = {Vedantam, Ramakrishna and Fischer, Ian and Huang, Jonathan and Murphy, Kevin},
    urldate = {2021-03-30},
    date = {2018-11-09},
    eprinttype = {arxiv},
    eprint = {1705.10762},
    keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Statistics - Machine Learning},
    file = {arXiv Fulltext PDF:/Users/Hendrik/Zotero/storage/KB67TLNP/Vedantam et al. - 2018 - Generative Models of Visually Grounded Imagination.pdf:application/pdf;arXiv.org Snapshot:/Users/Hendrik/Zotero/storage/39Y5UK8T/1705.html:text/html}
}

@article{wu_multimodal_2018,
    title = {Multimodal Generative Models for Scalable Weakly-Supervised Learning},
    url = {http://arxiv.org/abs/1802.05335},
    abstract = {Multiple modalities often co-occur when describing natural phenomena. Learning a joint representation of these modalities should yield deeper and more useful representations. Previous generative approaches to multi-modal input either do not learn a joint distribution or require additional computation to handle missing data. Here, we introduce a multimodal variational autoencoder ({MVAE}) that uses a product-of-experts inference network and a sub-sampled training paradigm to solve the multi-modal inference problem. Notably, our model shares parameters to efficiently learn under any combination of missing modalities. We apply the {MVAE} on four datasets and match state-of-the-art performance using many fewer parameters. In addition, we show that the {MVAE} is directly applicable to weakly-supervised learning, and is robust to incomplete supervision. We then consider two case studies, one of learning image transformations---edge detection, colorization, segmentation---as a set of modalities, followed by one of machine translation between two languages. We find appealing results across this range of tasks.},
    journaltitle = {{arXiv}:1802.05335 [cs, stat]},
    author = {Wu, Mike and Goodman, Noah},
    urldate = {2021-03-30},
    date = {2018-11-12},
    eprinttype = {arxiv},
    eprint = {1802.05335},
    keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
    file = {arXiv Fulltext PDF:/Users/Hendrik/Zotero/storage/LVSFF454/Wu and Goodman - 2018 - Multimodal Generative Models for Scalable Weakly-S.pdf:application/pdf;arXiv.org Snapshot:/Users/Hendrik/Zotero/storage/48FDVEUH/1802.html:text/html}
}


@article{johnson_mimic-cxr-jpg_2019,
    title = {{MIMIC}-{CXR}-{JPG}, a large publicly available database of labeled chest radiographs},
    url = {http://arxiv.org/abs/1901.07042},
    abstract = {Chest radiography is an extremely powerful imaging modality, allowing for a detailed inspection of a patient's thorax, but requiring specialized training for proper interpretation. With the advent of high performance general purpose computer vision algorithms, the accurate automated analysis of chest radiographs is becoming increasingly of interest to researchers. However, a key challenge in the development of these techniques is the lack of sufficient data. Here we describe {MIMIC}-{CXR}-{JPG} v2.0.0, a large dataset of 377,110 chest x-rays associated with 227,827 imaging studies sourced from the Beth Israel Deaconess Medical Center between 2011 - 2016. Images are provided with 14 labels derived from two natural language processing tools applied to the corresponding free-text radiology reports. {MIMIC}-{CXR}-{JPG} is derived entirely from the {MIMIC}-{CXR} database, and aims to provide a convenient processed version of {MIMIC}-{CXR}, as well as to provide a standard reference for data splits and image labels. All images have been de-identified to protect patient privacy. The dataset is made freely available to facilitate and encourage a wide range of research in medical computer vision.},
    journaltitle = {{arXiv}:1901.07042 [cs, eess]},
    author = {Johnson, Alistair E. W. and Pollard, Tom J. and Greenbaum, Nathaniel R. and Lungren, Matthew P. and Deng, Chih-ying and Peng, Yifan and Lu, Zhiyong and Mark, Roger G. and Berkowitz, Seth J. and Horng, Steven},
    urldate = {2021-03-31},
    date = {2019-11-14},
    eprinttype = {arxiv},
    eprint = {1901.07042},
    keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Electrical Engineering and Systems Science - Image and Video Processing},
    file = {arXiv Fulltext PDF:/Users/Hendrik/Zotero/storage/J6MBHIJ4/Johnson et al. - 2019 - MIMIC-CXR-JPG, a large publicly available database.pdf:application/pdf;arXiv.org Snapshot:/Users/Hendrik/Zotero/storage/TCH8K5K9/1901.html:text/html}
}

@book{bogachev2007measure,
    title = {Measure theory},
    author = {Bogachev, Vladimir I},
    volume = {1},
    year = {2007},
    publisher = {Springer Science \& Business Media}
}


@inproceedings{huang_neural_2018,
    title = {Neural Autoregressive Flows},
    url = {http://proceedings.mlr.press/v80/huang18d.html},
    abstract = {Normalizing flows and autoregressive models have been successfully combined to produce state-of-the-art results in density estimation, via Masked Autoregressive Flows ({MAF}) (Papamakarios et al., 20...},
    eventtitle = {International Conference on Machine Learning},
    pages = {2078--2087},
    booktitle = {International Conference on Machine Learning},
    publisher = {{PMLR}},
    author = {Huang, Chin-Wei and Krueger, David and Lacoste, Alexandre and Courville, Aaron},
    urldate = {2021-04-01},
    date = {2018-07-03},
    langid = {english},
    note = {{ISSN}: 2640-3498},
    file = {Full Text PDF:/Users/Hendrik/Zotero/storage/XRY3BRP2/Huang et al. - 2018 - Neural Autoregressive Flows.pdf:application/pdf;Snapshot:/Users/Hendrik/Zotero/storage/2XQCARBD/huang18d.html:text/html}
}


@article{hochreiter_long_1997,
    title = {Long Short-Term Memory},
    volume = {9},
    issn = {0899-7667},
    url = {https://doi.org/10.1162/neco.1997.9.8.1735},
    doi = {10.1162/neco.1997.9.8.1735},
    abstract = {Learning to store information over extended time intervals by recurrent backpropagation takes a very long time, mostly because of insufficient, decaying error backflow. We briefly review Hochreiter's (1991) analysis of this problem, then address it by introducing a novel, efficient, gradient based method called long short-term memory ({LSTM}). Truncating the gradient where this does not do harm, {LSTM} can learn to bridge minimal time lags in excess of 1000 discrete-time steps by enforcing constant error flow through constant error carousels within special units. Multiplicative gate units learn to open and close access to the constant error flow. {LSTM} is local in space and time; its computational complexity per time step and weight is O. 1. Our experiments with artificial data involve local, distributed, real-valued, and noisy pattern representations. In comparisons with real-time recurrent learning, back propagation through time, recurrent cascade correlation, Elman nets, and neural sequence chunking, {LSTM} leads to many more successful runs, and learns much faster. {LSTM} also solves complex, artificial long-time-lag tasks that have never been solved by previous recurrent network algorithms.},
    pages = {1735--1780},
    number = {8},
    journaltitle = {Neural Computation},
    shortjournal = {Neural Computation},
    author = {Hochreiter, Sepp and Schmidhuber, Jürgen},
    urldate = {2021-04-01},
    date = {1997-11-15},
    file = {Full Text PDF:/Users/Hendrik/Zotero/storage/HCEHAKYR/Hochreiter and Schmidhuber - 1997 - Long Short-Term Memory.pdf:application/pdf;Snapshot:/Users/Hendrik/Zotero/storage/6USAAPTG/Long-Short-Term-Memory.html:text/html}
}


@article{dinh_nice_2015,
    title = {{NICE}: Non-linear Independent Components Estimation},
    url = {http://arxiv.org/abs/1410.8516},
    shorttitle = {{NICE}},
    abstract = {We propose a deep learning framework for modeling complex high-dimensional densities called Non-linear Independent Component Estimation ({NICE}). It is based on the idea that a good representation is one in which the data has a distribution that is easy to model. For this purpose, a non-linear deterministic transformation of the data is learned that maps it to a latent space so as to make the transformed data conform to a factorized distribution, i.e., resulting in independent latent variables. We parametrize this transformation so that computing the Jacobian determinant and inverse transform is trivial, yet we maintain the ability to learn complex non-linear transformations, via a composition of simple building blocks, each based on a deep neural network. The training criterion is simply the exact log-likelihood, which is tractable. Unbiased ancestral sampling is also easy. We show that this approach yields good generative models on four image datasets and can be used for inpainting.},
    journaltitle = {{arXiv}:1410.8516 [cs]},
    author = {Dinh, Laurent and Krueger, David and Bengio, Yoshua},
    urldate = {2021-04-01},
    date = {2015-04-10},
    eprinttype = {arxiv},
    eprint = {1410.8516},
    keywords = {Computer Science - Machine Learning},
    file = {arXiv Fulltext PDF:/Users/Hendrik/Zotero/storage/STEZXYWX/Dinh et al. - 2015 - NICE Non-linear Independent Components Estimation.pdf:application/pdf;arXiv.org Snapshot:/Users/Hendrik/Zotero/storage/A6T37WCB/1410.html:text/html}
}


@article{kingma_glow_2018,
    title = {Glow: Generative Flow with Invertible 1x1 Convolutions},
    url = {http://arxiv.org/abs/1807.03039},
    shorttitle = {Glow},
    abstract = {Flow-based generative models (Dinh et al., 2014) are conceptually attractive due to tractability of the exact log-likelihood, tractability of exact latent-variable inference, and parallelizability of both training and synthesis. In this paper we propose Glow, a simple type of generative flow using an invertible 1x1 convolution. Using our method we demonstrate a significant improvement in log-likelihood on standard benchmarks. Perhaps most strikingly, we demonstrate that a generative model optimized towards the plain log-likelihood objective is capable of efficient realistic-looking synthesis and manipulation of large images. The code for our model is available at https://github.com/openai/glow},
    journaltitle = {{arXiv}:1807.03039 [cs, stat]},
    author = {Kingma, Diederik P. and Dhariwal, Prafulla},
    urldate = {2021-04-01},
    date = {2018-07-10},
    eprinttype = {arxiv},
    eprint = {1807.03039},
    keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Statistics - Machine Learning}
}


@inproceedings{prenger_waveglow_2019,
    title = {Waveglow: A Flow-based Generative Network for Speech Synthesis},
    doi = {10.1109/ICASSP.2019.8683143},
    shorttitle = {Waveglow},
    abstract = {In this paper we propose {WaveGlow}: a flow-based network capable of generating high quality speech from mel-spectrograms. {WaveGlow} combines insights from Glow [1] and {WaveNet} [2] in order to provide fast, efficient and high-quality audio synthesis, without the need for auto-regression. {WaveGlow} is implemented using only a single network, trained using only a single cost function: maximizing the likelihood of the training data, which makes the training procedure simple and stable. Our {PyTorch} implementation produces audio samples at a rate of more than 500 {kHz} on an {NVIDIA} V100 {GPU}. Mean Opinion Scores show that it delivers audio quality as good as the best publicly available {WaveNet} implementation. All code will be made publicly available online [3].},
    eventtitle = {{ICASSP} 2019 - 2019 {IEEE} International Conference on Acoustics, Speech and Signal Processing ({ICASSP})},
    pages = {3617--3621},
    booktitle = {{ICASSP} 2019 - 2019 {IEEE} International Conference on Acoustics, Speech and Signal Processing ({ICASSP})},
    author = {Prenger, R. and Valle, R. and Catanzaro, B.},
    date = {2019-05},
    note = {{ISSN}: 2379-190X},
    keywords = {Audio Synthesis, Deep Learning, Generative models, Text-to-speech},
    file = {IEEE Xplore Abstract Record:/Users/Hendrik/Zotero/storage/HDWS5R4T/8683143.html:text/html;IEEE Xplore Full Text PDF:/Users/Hendrik/Zotero/storage/3SGZ4BAC/Prenger et al. - 2019 - Waveglow A Flow-based Generative Network for Spee.pdf:application/pdf}
}


@inproceedings{ho_flow_2019,
    title = {Flow++: Improving Flow-Based Generative Models with Variational Dequantization and Architecture Design},
    url = {http://proceedings.mlr.press/v97/ho19a.html},
    shorttitle = {Flow++},
    abstract = {Flow-based generative models are powerful exact likelihood models with efficient sampling and inference. Despite their computational efficiency, flow-based models generally have much worse density ...},
    eventtitle = {International Conference on Machine Learning},
    pages = {2722--2730},
    booktitle = {International Conference on Machine Learning},
    publisher = {{PMLR}},
    author = {Ho, Jonathan and Chen, Xi and Srinivas, Aravind and Duan, Yan and Abbeel, Pieter},
    urldate = {2021-04-01},
    date = {2019-05-24},
    langid = {english},
    note = {{ISSN}: 2640-3498},
    file = {Full Text PDF:/Users/Hendrik/Zotero/storage/LQ3MUA3C/Ho et al. - 2019 - Flow++ Improving Flow-Based Generative Models wit.pdf:application/pdf;Snapshot:/Users/Hendrik/Zotero/storage/X94P6YD7/ho19a.html:text/html}
}


@inproceedings{behrmann_invertible_2019,
    title = {Invertible Residual Networks},
    url = {http://proceedings.mlr.press/v97/behrmann19a.html},
    abstract = {We show that standard {ResNet} architectures can be made invertible, allowing the same model to be used for classification, density estimation, and generation. Typically, enforcing invertibility requ...},
    eventtitle = {International Conference on Machine Learning},
    pages = {573--582},
    booktitle = {International Conference on Machine Learning},
    publisher = {{PMLR}},
    author = {Behrmann, Jens and Grathwohl, Will and Chen, Ricky T. Q. and Duvenaud, David and Jacobsen, Joern-Henrik},
    urldate = {2021-04-02},
    date = {2019-05-24},
    langid = {english},
    note = {{ISSN}: 2640-3498},
    file = {Full Text PDF:/Users/Hendrik/Zotero/storage/4MI5NR64/Behrmann et al. - 2019 - Invertible Residual Networks.pdf:application/pdf;Snapshot:/Users/Hendrik/Zotero/storage/CNUKZKKM/behrmann19a.html:text/html}
}


@article{chen_residual_2020,
    title = {Residual Flows for Invertible Generative Modeling},
    url = {http://arxiv.org/abs/1906.02735},
    abstract = {Flow-based generative models parameterize probability distributions through an invertible transformation and can be trained by maximum likelihood. Invertible residual networks provide a flexible family of transformations where only Lipschitz conditions rather than strict architectural constraints are needed for enforcing invertibility. However, prior work trained invertible residual networks for density estimation by relying on biased log-density estimates whose bias increased with the network's expressiveness. We give a tractable unbiased estimate of the log density using a "Russian roulette" estimator, and reduce the memory required during training by using an alternative infinite series for the gradient. Furthermore, we improve invertible residual blocks by proposing the use of activation functions that avoid derivative saturation and generalizing the Lipschitz condition to induced mixed norms. The resulting approach, called Residual Flows, achieves state-of-the-art performance on density estimation amongst flow-based models, and outperforms networks that use coupling blocks at joint generative and discriminative modeling.},
    journaltitle = {{arXiv}:1906.02735 [cs, stat]},
    author = {Chen, Ricky T. Q. and Behrmann, Jens and Duvenaud, David and Jacobsen, Jörn-Henrik},
    urldate = {2021-04-02},
    date = {2020-07-23},
    eprinttype = {arxiv},
    eprint = {1906.02735},
    keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
    file = {arXiv Fulltext PDF:/Users/Hendrik/Zotero/storage/UDQ2Q5YG/Chen et al. - 2020 - Residual Flows for Invertible Generative Modeling.pdf:application/pdf}
}


@article{berg_sylvester_2019,
    title = {Sylvester Normalizing Flows for Variational Inference},
    url = {http://arxiv.org/abs/1803.05649},
    abstract = {Variational inference relies on flexible approximate posterior distributions. Normalizing flows provide a general recipe to construct flexible variational posteriors. We introduce Sylvester normalizing flows, which can be seen as a generalization of planar flows. Sylvester normalizing flows remove the well-known single-unit bottleneck from planar flows, making a single transformation much more flexible. We compare the performance of Sylvester normalizing flows against planar flows and inverse autoregressive flows and demonstrate that they compare favorably on several datasets.},
    journaltitle = {{arXiv}:1803.05649 [cs, stat]},
    author = {Berg, Rianne van den and Hasenclever, Leonard and Tomczak, Jakub M. and Welling, Max},
    urldate = {2021-04-02},
    date = {2019-02-20},
    eprinttype = {arxiv},
    eprint = {1803.05649},
    keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Statistics - Machine Learning, Statistics - Methodology},
    file = {arXiv Fulltext PDF:/Users/Hendrik/Zotero/storage/8QMQLHTS/Berg et al. - 2019 - Sylvester Normalizing Flows for Variational Infere.pdf:application/pdf;arXiv.org Snapshot:/Users/Hendrik/Zotero/storage/9WA6H4TB/1803.html:text/html}
}


@inproceedings{sutter_generalized_2020,
    title = {Generalized Multimodal {ELBO}},
    url = {https://openreview.net/forum?id=5Y21V0RDBV},
    abstract = {Multiple data types naturally co-occur when describing real-world phenomena and learning from them is a long-standing goal in machine learning research. However, existing self-supervised generative...},
    eventtitle = {International Conference on Learning Representations},
    author = {Sutter, Thomas Marco and Daunhawer, Imant and Vogt, Julia E.},
    urldate = {2021-04-02},
    date = {2020-09-28},
    langid = {english},
    file = {Full Text PDF:/Users/Hendrik/Zotero/storage/I754DQ4N/Sutter et al. - 2020 - Generalized Multimodal ELBO.pdf:application/pdf;Snapshot:/Users/Hendrik/Zotero/storage/93R3JL2U/forum.html:text/html}
}


@inproceedings{liu_deep_2015,
    title = {Deep Learning Face Attributes in the Wild},
    url = {https://openaccess.thecvf.com/content_iccv_2015/html/Liu_Deep_Learning_Face_ICCV_2015_paper.html},
    eventtitle = {Proceedings of the {IEEE} International Conference on Computer Vision},
    pages = {3730--3738},
    author = {Liu, Ziwei and Luo, Ping and Wang, Xiaogang and Tang, Xiaoou},
    urldate = {2021-04-08},
    date = {2015},
    file = {Full Text PDF:/Users/Hendrik/Zotero/storage/3EKADQG2/Liu et al. - 2015 - Deep Learning Face Attributes in the Wild.pdf:application/pdf;Snapshot:/Users/Hendrik/Zotero/storage/J2XUSGJI/Liu_Deep_Learning_Face_ICCV_2015_paper.html:text/html}
}


@article{oord_conditional_2016,
    title = {Conditional Image Generation with {PixelCNN} Decoders},
    url = {http://arxiv.org/abs/1606.05328},
    abstract = {This work explores conditional image generation with a new image density model based on the {PixelCNN} architecture. The model can be conditioned on any vector, including descriptive labels or tags, or latent embeddings created by other networks. When conditioned on class labels from the {ImageNet} database, the model is able to generate diverse, realistic scenes representing distinct animals, objects, landscapes and structures. When conditioned on an embedding produced by a convolutional network given a single image of an unseen face, it generates a variety of new portraits of the same person with different facial expressions, poses and lighting conditions. We also show that conditional {PixelCNN} can serve as a powerful decoder in an image autoencoder. Additionally, the gated convolutional layers in the proposed model improve the log-likelihood of {PixelCNN} to match the state-of-the-art performance of {PixelRNN} on {ImageNet}, with greatly reduced computational cost.},
    journaltitle = {{arXiv}:1606.05328 [cs]},
    author = {Oord, Aaron van den and Kalchbrenner, Nal and Vinyals, Oriol and Espeholt, Lasse and Graves, Alex and Kavukcuoglu, Koray},
    urldate = {2021-04-02},
    date = {2016-06-18},
    eprinttype = {arxiv},
    eprint = {1606.05328},
    keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning},
    file = {arXiv Fulltext PDF:/Users/Hendrik/Zotero/storage/CVFIJQ4E/Oord et al. - 2016 - Conditional Image Generation with PixelCNN Decoder.pdf:application/pdf;arXiv.org Snapshot:/Users/Hendrik/Zotero/storage/Q6DVZKM7/1606.html:text/html}
}
@inproceedings{imagenet_cvpr09,
    AUTHOR = {Deng, J. and Dong, W. and Socher, R. and Li, L.-J. and Li, K. and Fei-Fei, L.},
    TITLE = {{ImageNet: A Large-Scale Hierarchical Image Database}},
    BOOKTITLE = {CVPR09},
    YEAR = {2009},
    BIBSOURCE = "http://www.image-net.org/papers/imagenet_cvpr09.bib" }

@article{huang2018densely,
    title = {Densely connected convolutional networks. arXiv 2016},
    author = {Huang, Gao and Liu, Zhuang and Weinberger, Kilian Q and van der Maaten, Laurens},
    journal = {arXiv preprint arXiv:1608.06993},
    volume = {1608},
    year = {2018}
}

@misc{vahdat2021nvae,
    title = {NVAE: A Deep Hierarchical Variational Autoencoder},
    author = {Arash Vahdat and Jan Kautz},
    year = {2021},
    eprint = {2007.03898},
    archivePrefix = {arXiv},
    primaryClass = {stat.ML}
}

@article{zhao2017towards,
    title = {Towards deeper understanding of variational autoencoding models},
    author = {Zhao, Shengjia and Song, Jiaming and Ermon, Stefano},
    journal = {arXiv preprint arXiv:1702.08658},
    year = {2017}
}

@misc{oord2018neural,
    title = {Neural Discrete Representation Learning},
    author = {Aaron van den Oord and Oriol Vinyals and Koray Kavukcuoglu},
    year = {2018},
    eprint = {1711.00937},
    archivePrefix = {arXiv},
    primaryClass = {cs.LG}
}

@inproceedings{liu2015faceattributes,
    title = {Deep Learning Face Attributes in the Wild},
    author = {Liu, Ziwei and Luo, Ping and Wang, Xiaogang and Tang, Xiaoou},
    booktitle = {Proceedings of International Conference on Computer Vision (ICCV)},
    month = {December},
    year = {2015}
}

@article{scikit,
    title = {Scikit-learn: Machine learning in Python},
    author = {Pedregosa, Fabian and Varoquaux, Ga{\"e}l and Gramfort, Alexandre and Michel, Vincent and Thirion, Bertrand and Grisel, Olivier and Blondel, Mathieu and Prettenhofer, Peter and Weiss, Ron and Dubourg, Vincent and others},
    journal = {the Journal of machine Learning research},
    volume = {12},
    pages = {2825--2830},
    year = {2011},
    publisher = {JMLR. org}
}


@article{lecun-mnisthandwrittendigit-2010,
    added-at = {2010-06-28T21:16:30.000+0200},
    author = {LeCun, Yann and Cortes, Corinna},
    biburl = {https://www.bibsonomy.org/bibtex/2935bad99fa1f65e03c25b315aa3c1032/mhwombat},
    groups = {public},
    howpublished = {http://yann.lecun.com/exdb/mnist/},
    interhash = {21b9d0558bd66279df9452562df6e6f3},
    intrahash = {935bad99fa1f65e03c25b315aa3c1032},
    keywords = {MSc _checked character_recognition mnist network neural},
    lastchecked = {2016-01-14 14:24:11},
    timestamp = {2016-07-12T19:25:30.000+0200},
    title = {{MNIST} handwritten digit database},
    url = {http://yann.lecun.com/exdb/mnist/},
    username = {mhwombat},
    year = 2010
}

@article{adam,
    title = {A method for stochastic optimization. arXiv 2014},
    author = {Kingma, Diederik P and Ba, J Adam},
    journal = {arXiv preprint arXiv:1412.6980},
    volume = {434},
    year = {2019}
}

@misc{kingma2014autoencoding,
    title = {Auto-Encoding Variational Bayes},
    author = {Diederik P Kingma and Max Welling},
    year = {2014},
    eprint = {1312.6114},
    archivePrefix = {arXiv},
    primaryClass = {stat.ML}
}

@misc{doersch2016tutorial,
    title = {Tutorial on Variational Autoencoders},
    author = {Carl Doersch},
    year = {2016},
    eprint = {1606.05908},
    archivePrefix = {arXiv},
    primaryClass = {stat.ML}
}

@inproceedings{wu2018multimodal,
    title = {Multimodal generative models for scalable weakly-supervised learning},
    author = {Wu, Mike and Goodman, Noah},
    booktitle = {Advances in Neural Information Processing Systems},
    pages = {5575--5585},
    year = {2018}
}

@article{netzer2011reading,
    title = {Reading digits in natural images with unsupervised feature learning},
    author = {Netzer, Yuval and Wang, Tao and Coates, Adam and Bissacco, Alessandro and Wu, Bo and Ng, Andrew Y},
    year = {2011}
}
@inproceedings{shi2019variational,
    title = {Variational mixture-of-experts autoencoders for multi-modal deep generative models},
    author = {Shi, Yuge and Siddharth, Narayanaswamy and Paige, Brooks and Torr, Philip},
    booktitle = {Advances in Neural Information Processing Systems},
    pages = {15718--15729},
    year = {2019}
}

@inproceedings{liu2015deep,
    title = {Deep learning face attributes in the wild},
    author = {Liu, Ziwei and Luo, Ping and Wang, Xiaogang and Tang, Xiaoou},
    booktitle = {Proceedings of the IEEE international conference on computer vision},
    pages = {3730--3738},
    year = {2015}
}

@article{thomas_multimodal,
    title = {Multimodal Generative Learning Utilizing Jensen-Shannon-Divergence},
    author = {Sutter, Thomas M and Daunhawer, Imant and Vogt, Julia E},
    journal = {arXiv preprint arXiv:2006.08242},
    year = {2020}
}

@article{bowman2015generating,
    title = {Generating sentences from a continuous space},
    author = {Bowman, Samuel R and Vilnis, Luke and Vinyals, Oriol and Dai, Andrew M and Jozefowicz, Rafal and Bengio, Samy},
    journal = {arXiv preprint arXiv:1511.06349},
    year = {2015}
}

@article{gulrajani2016pixelvae,
    title = {Pixelvae: A latent variable model for natural images},
    author = {Gulrajani, Ishaan and Kumar, Kundan and Ahmed, Faruk and Taiga, Adrien Ali and Visin, Francesco and Vazquez, David and Courville, Aaron},
    journal = {arXiv preprint arXiv:1611.05013},
    year = {2016}
}

@article{kingma2015variational,
    title = {Variational dropout and the local reparameterization trick},
    author = {Kingma, Diederik P and Salimans, Tim and Welling, Max},
    journal = {arXiv preprint arXiv:1506.02557},
    year = {2015}
}

@inproceedings{das2017visual,
    title = {Visual dialog},
    author = {Das, Abhishek and Kottur, Satwik and Gupta, Khushi and Singh, Avi and Yadav, Deshraj and Moura, Jos{\'e} MF and Parikh, Devi and Batra, Dhruv},
    booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
    pages = {326--335},
    year = {2017}
}


@inproceedings{antol2015vqa,
    title = {Vqa: Visual question answering},
    author = {Antol, Stanislaw and Agrawal, Aishwarya and Lu, Jiasen and Mitchell, Margaret and Batra, Dhruv and Zitnick, C Lawrence and Parikh, Devi},
    booktitle = {Proceedings of the IEEE international conference on computer vision},
    pages = {2425--2433},
    year = {2015}
}

@article{dosovitskiy2016generating,
    title = {Generating images with perceptual similarity metrics based on deep networks},
    author = {Dosovitskiy, Alexey and Brox, Thomas},
    journal = {arXiv preprint arXiv:1602.02644},
    year = {2016}
}

@inproceedings{kovaleva2020towards,
    title = {Towards Visual Dialog for Radiology},
    author = {Kovaleva, Olga and Shivade, Chaitanya and Kashyap, Satyananda and Kanjaria, Karina and Wu, Joy and Ballah, Deddeh and Coy, Adam and Karargyris, Alexandros and Guo, Yufan and Beymer, David Beymer and others},
    booktitle = {Proceedings of the 19th SIGBioMed Workshop on Biomedical Language Processing},
    pages = {60--69},
    year = {2020}
}

@inproceedings{he2016deep,
    title = {Deep residual learning for image recognition},
    author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
    booktitle = {Proceedings of the IEEE conference on computer vision and pattern recognition},
    pages = {770--778},
    year = {2016}
}


@software{mimic_repsep,
    title = {Jimmy2027/Mimic\_RepSep},
    rights = {{GPL}-3.0 License ,                 {GPL}-3.0 License},
    url = {https://github.com/Jimmy2027/Mimic_RepSep},
    abstract = {Contribute to Jimmy2027/Mimic\_RepSep development by creating an account on {GitHub}.},
    author = {Hendrik{\textbackslash}\_Klug},
    urldate = {2021-02-16},
    date = {2021-02-15},
    note = {original-date: 2021-01-16T14:03:58Z}
}

@article{ioanas2018reproducible,
    title = {Reproducible self-publishing for Python-based research},
    author = {Ioanas, Horea-Ioan and Rudin, Markus},
    journal = {EuroSciPy, August},
    year = {2018}
}


@inproceedings{
thomas_gener-ELBO,
    title = {Generalized Multimodal {ELBO}},
    author = {Thomas Marco Sutter and Imant Daunhawer and Julia E Vogt},
    booktitle = {International Conference on Learning Representations},
    year = {2021},
}

@article{rajpurkar2017chexnet,
    title = {Chexnet: Radiologist-level pneumonia detection on chest x-rays with deep learning},
    author = {Rajpurkar, Pranav and Irvin, Jeremy and Zhu, Kaylie and Yang, Brandon and Mehta, Hershel and Duan, Tony and Ding, Daisy and Bagul, Aarti and Langlotz, Curtis and Shpanskaya, Katie and others},
    journal = {arXiv preprint arXiv:1711.05225},
    year = {2017}
}

@article{johnson2019mimic,
    title = {MIMIC-CXR-JPG, a large publicly available database of labeled chest radiographs},
    author = {Johnson, Alistair EW and Pollard, Tom J and Greenbaum, Nathaniel R and Lungren, Matthew P and Deng, Chih-ying and Peng, Yifan and Lu, Zhiyong and Mark, Roger G and Berkowitz, Seth J and Horng, Steven},
    journal = {arXiv preprint arXiv:1901.07042},
    year = {2019}
}


@article{dinh_density_2017,
    title = {Density estimation using Real {NVP}},
    url = {http://arxiv.org/abs/1605.08803},
    abstract = {Unsupervised learning of probabilistic models is a central yet challenging problem in machine learning. Specifically, designing models with tractable learning, sampling, inference and evaluation is crucial in solving this task. We extend the space of such models using real-valued non-volume preserving (real {NVP}) transformations, a set of powerful invertible and learnable transformations, resulting in an unsupervised learning algorithm with exact log-likelihood computation, exact sampling, exact inference of latent variables, and an interpretable latent space. We demonstrate its ability to model natural images on four datasets through sampling, log-likelihood evaluation and latent variable manipulations.},
    journaltitle = {{arXiv}:1605.08803 [cs, stat]},
    author = {Dinh, Laurent and Sohl-Dickstein, Jascha and Bengio, Samy},
    urldate = {2021-07-29},
    date = {2017-02-27},
    eprinttype = {arxiv},
    eprint = {1605.08803},
    keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing, Statistics - Machine Learning}
}




@article{burda_importance_2016,
    title = {Importance Weighted Autoencoders},
    url = {http://arxiv.org/abs/1509.00519},
    abstract = {The variational autoencoder ({VAE}; Kingma, Welling (2014)) is a recently proposed generative model pairing a top-down generative network with a bottom-up recognition network which approximates posterior inference. It typically makes strong assumptions about posterior inference, for instance that the posterior distribution is approximately factorial, and that its parameters can be approximated with nonlinear regression from the observations. As we show empirically, the {VAE} objective can lead to overly simplified representations which fail to use the network's entire modeling capacity. We present the importance weighted autoencoder ({IWAE}), a generative model with the same architecture as the {VAE}, but which uses a strictly tighter log-likelihood lower bound derived from importance weighting. In the {IWAE}, the recognition network uses multiple samples to approximate the posterior, giving it increased flexibility to model complex posteriors which do not fit the {VAE} modeling assumptions. We show empirically that {IWAEs} learn richer latent space representations than {VAEs}, leading to improved test log-likelihood on density estimation benchmarks.},
    journaltitle = {{arXiv}:1509.00519 [cs, stat]},
    author = {Burda, Yuri and Grosse, Roger and Salakhutdinov, Ruslan},
    urldate = {2021-07-29},
    date = {2016-11-07},
    eprinttype = {arxiv},
    eprint = {1509.00519},
    keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, \_tablet, to\_read},
    file = {arXiv.org Snapshot:/Users/Hendrik/Zotero/storage/NGP9N8LJ/1509.html:text/html;Burda et al_2016_Importance Weighted Autoencoders.pdf:/Users/Hendrik/zotfile/Burda et al_2016_Importance Weighted Autoencoders.pdf:application/pdf}
}


@inproceedings{nowozin_debiasing_2018,
    title = {Debiasing Evidence Approximations: On Importance-weighted Autoencoders and Jackknife Variational Inference},
    url = {https://www.microsoft.com/en-us/research/publication/debiasing-evidence-approximations-importance-weighted-autoencoders-jackknife-variational-inference/},
    shorttitle = {Debiasing Evidence Approximations},
    abstract = {The importance-weighted autoencoder ({IWAE}) approach of Burda et al. defines a sequence of increasingly tighter bounds on the marginal likelihood of latent variable models. Recently, Cremer et al. reinterpreted the {IWAE} bounds as ordinary variational evidence lower bounds ({ELBO}) applied to increasingly accurate variational distributions. In this work, we provide yet another perspective on the […]},
    eventtitle = {{ICLR} 2018 Conference},
    author = {Nowozin, Sebastian},
    urldate = {2021-07-30},
    date = {2018-02-15},
    langid = {american},
    keywords = {\_tablet},
    file = {Nowozin_2018_Debiasing Evidence Approximations.pdf:/Users/Hendrik/zotfile/Nowozin_2018_Debiasing Evidence Approximations.pdf:application/pdf;Snapshot:/Users/Hendrik/Zotero/storage/2P4TKEGT/debiasing-evidence-approximations-importance-weighted-autoencoders-jackknife-variational-infere.html:text/html}
}

@inproceedings{precision_recall_distributions,
    title = {{Assessing Generative Models via Precision and Recall}},
    author = {Sajjadi, Mehdi~S.~M. and Bachem, Olivier and Lu{\v c}i{\'c}, Mario and Bousquet, Olivier and Gelly, Sylvain},
    booktitle = {{Advances in Neural Information Processing Systems (NeurIPS)}},
    year = {2018} }


@article{akiba_optuna_2019,
    title = {Optuna: A Next-generation Hyperparameter Optimization Framework},
    url = {http://arxiv.org/abs/1907.10902},
    shorttitle = {Optuna},
    abstract = {The purpose of this study is to introduce new design-criteria for next-generation hyperparameter optimization software. The criteria we propose include (1) define-by-run {API} that allows users to construct the parameter search space dynamically, (2) efficient implementation of both searching and pruning strategies, and (3) easy-to-setup, versatile architecture that can be deployed for various purposes, ranging from scalable distributed computing to light-weight experiment conducted via interactive interface. In order to prove our point, we will introduce Optuna, an optimization software which is a culmination of our effort in the development of a next generation optimization software. As an optimization software designed with define-by-run principle, Optuna is particularly the first of its kind. We will present the design-techniques that became necessary in the development of the software that meets the above criteria, and demonstrate the power of our new design through experimental results and real world applications. Our software is available under the {MIT} license (https://github.com/pfnet/optuna/).},
    journaltitle = {{arXiv}:1907.10902 [cs, stat]},
    author = {Akiba, Takuya and Sano, Shotaro and Yanase, Toshihiko and Ohta, Takeru and Koyama, Masanori},
    urldate = {2021-08-08},
    date = {2019-07-25},
    eprinttype = {arxiv},
    eprint = {1907.10902},
    keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
    file = {Akiba et al_2019_Optuna.pdf:/Users/Hendrik/zotfile/Akiba et al_2019_Optuna.pdf:application/pdf}
}


