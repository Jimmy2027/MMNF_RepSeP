@article{sutter_learning_nodate,
    title = {Learning from multiple data types utilizing abstract mean functions},
    pages = {4},
    author = {Sutter, Thonas M},
    langid = {english},
    file = {Sutter - Learning from multiple data types utilizing abstra.pdf:/Users/Hendrik/Zotero/storage/M2B8W74M/Sutter - Learning from multiple data types utilizing abstra.pdf:application/pdf}
}

@article{rezende_variational_2016,
    title = {Variational Inference with Normalizing Flows},
    url = {http://arxiv.org/abs/1505.05770},
    abstract = {The choice of approximate posterior distribution is one of the core problems in variational inference. Most applications of variational inference employ simple families of posterior approximations in order to allow for efficient inference, focusing on mean-field or other simple structured approximations. This restriction has a significant impact on the quality of inferences made using variational methods. We introduce a new approach for specifying flexible, arbitrarily complex and scalable approximate posterior distributions. Our approximations are distributions constructed through a normalizing flow, whereby a simple initial density is transformed into a more complex one by applying a sequence of invertible transformations until a desired level of complexity is attained. We use this view of normalizing flows to develop categories of finite and infinitesimal flows and provide a unified view of approaches for constructing rich posterior approximations. We demonstrate that the theoretical advantages of having posteriors that better match the true posterior, combined with the scalability of amortized variational approaches, provides a clear improvement in performance and applicability of variational inference.},
    journaltitle = {{arXiv}:1505.05770 [cs, stat]},
    author = {Rezende, Danilo Jimenez and Mohamed, Shakir},
    urldate = {2021-03-22},
    date = {2016-06-14},
    eprinttype = {arxiv},
    eprint = {1505.05770},
    keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Statistics - Computation, Statistics - Machine Learning, Statistics - Methodology},
    file = {arXiv Fulltext PDF:/Users/Hendrik/Zotero/storage/EFPQNS97/Rezende and Mohamed - 2016 - Variational Inference with Normalizing Flows.pdf:application/pdf;arXiv.org Snapshot:/Users/Hendrik/Zotero/storage/VSGUU2S3/1505.html:text/html}
}

@article{kingma_improving_2017,
    title = {Improving Variational Inference with Inverse Autoregressive Flow},
    url = {http://arxiv.org/abs/1606.04934},
    abstract = {The framework of normalizing flows provides a general strategy for flexible variational inference of posteriors over latent variables. We propose a new type of normalizing flow, inverse autoregressive flow ({IAF}), that, in contrast to earlier published flows, scales well to high-dimensional latent spaces. The proposed flow consists of a chain of invertible transformations, where each transformation is based on an autoregressive neural network. In experiments, we show that {IAF} significantly improves upon diagonal Gaussian approximate posteriors. In addition, we demonstrate that a novel type of variational autoencoder, coupled with {IAF}, is competitive with neural autoregressive models in terms of attained log-likelihood on natural images, while allowing significantly faster synthesis.},
    journaltitle = {{arXiv}:1606.04934 [cs, stat]},
    author = {Kingma, Diederik P. and Salimans, Tim and Jozefowicz, Rafal and Chen, Xi and Sutskever, Ilya and Welling, Max},
    urldate = {2021-03-22},
    date = {2017-01-30},
    eprinttype = {arxiv},
    eprint = {1606.04934},
    keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
    file = {arXiv Fulltext PDF:/Users/Hendrik/Zotero/storage/XL6NVUH7/Kingma et al. - 2017 - Improving Variational Inference with Inverse Autor.pdf:application/pdf;arXiv.org Snapshot:/Users/Hendrik/Zotero/storage/DB4II29Q/1606.html:text/html}
}

@article{kobyzev_normalizing_2020,
    title = {Normalizing Flows: An Introduction and Review of Current Methods},
    issn = {1939-3539},
    doi = {10.1109/TPAMI.2020.2992934},
    shorttitle = {Normalizing Flows},
    abstract = {Normalizing Flows are generative models which produce tractable distributions where both sampling and density evaluation can be efficient and exact. The goal of this survey article is to give a coherent and comprehensive review of the literature around the construction and use of Normalizing Flows for distribution learning. We aim to provide context and explanation of the models, review current state-of-the-art literature, and identify open questions and promising future directions.},
    pages = {1--1},
    journaltitle = {{IEEE} Transactions on Pattern Analysis and Machine Intelligence},
    author = {Kobyzev, I. and Prince, S. and Brubaker, M.},
    date = {2020},
    note = {Conference Name: {IEEE} Transactions on Pattern Analysis and Machine Intelligence},
    keywords = {Computational modeling, Context modeling, Density estimation, Estimation, Generative models, Invertible neural networks, Jacobian matrices, Mathematical model, Normalizing flows, Random variables, Training, Variational inference},
    file = {IEEE Xplore Full Text PDF:/Users/Hendrik/Zotero/storage/7IGXE2K7/Kobyzev et al. - 2020 - Normalizing Flows An Introduction and Review of C.pdf:application/pdf}
}

@article{papamakarios_normalizing_2019,
    title = {Normalizing Flows for Probabilistic Modeling and Inference},
    url = {http://arxiv.org/abs/1912.02762},
    abstract = {Normalizing ﬂows provide a general mechanism for deﬁning expressive probability distributions, only requiring the speciﬁcation of a (usually simple) base distribution and a series of bijective transformations. There has been much recent work on normalizing ﬂows, ranging from improving their expressive power to expanding their application. We believe the ﬁeld has now matured and is in need of a uniﬁed perspective. In this review, we attempt to provide such a perspective by describing ﬂows through the lens of probabilistic modeling and inference. We place special emphasis on the fundamental principles of ﬂow design, and discuss foundational topics such as expressive power and computational trade-oﬀs. We also broaden the conceptual framing of ﬂows by relating them to more general probability transformations. Lastly, we summarize the use of ﬂows for tasks such as generative modeling, approximate inference, and supervised learning.},
    journaltitle = {{arXiv}:1912.02762 [cs, stat]},
    author = {Papamakarios, George and Nalisnick, Eric and Rezende, Danilo Jimenez and Mohamed, Shakir and Lakshminarayanan, Balaji},
    urldate = {2021-03-24},
    date = {2019-12-05},
    langid = {english},
    eprinttype = {arxiv},
    eprint = {1912.02762},
    keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
    file = {Papamakarios et al. - 2019 - Normalizing Flows for Probabilistic Modeling and I.pdf:/Users/Hendrik/Zotero/storage/76PKLB7E/Papamakarios et al. - 2019 - Normalizing Flows for Probabilistic Modeling and I.pdf:application/pdf}
}

@article{baltrusaitis_multimodal_2019,
    title = {Multimodal Machine Learning: A Survey and Taxonomy},
    volume = {41},
    issn = {1939-3539},
    doi = {10.1109/TPAMI.2018.2798607},
    shorttitle = {Multimodal Machine Learning},
    abstract = {Our experience of the world is multimodal - we see objects, hear sounds, feel texture, smell odors, and taste flavors. Modality refers to the way in which something happens or is experienced and a research problem is characterized as multimodal when it includes multiple such modalities. In order for Artificial Intelligence to make progress in understanding the world around us, it needs to be able to interpret such multimodal signals together. Multimodal machine learning aims to build models that can process and relate information from multiple modalities. It is a vibrant multi-disciplinary field of increasing importance and with extraordinary potential. Instead of focusing on specific multimodal applications, this paper surveys the recent advances in multimodal machine learning itself and presents them in a common taxonomy. We go beyond the typical early and late fusion categorization and identify broader challenges that are faced by multimodal machine learning, namely: representation, translation, alignment, fusion, and co-learning. This new taxonomy will enable researchers to better understand the state of the field and identify directions for future research.},
    pages = {423--443},
    number = {2},
    journaltitle = {{IEEE} Transactions on Pattern Analysis and Machine Intelligence},
    author = {Baltrušaitis, T. and Ahuja, C. and Morency, L.},
    date = {2019-02},
    note = {Conference Name: {IEEE} Transactions on Pattern Analysis and Machine Intelligence},
    keywords = {Hidden Markov models, introductory, machine learning, Media, Multimedia communication, Multimodal, Speech, Speech recognition, Streaming media, survey, Visualization},
    file = {IEEE Xplore Abstract Record:/Users/Hendrik/Zotero/storage/GRLQHZ3N/8269806.html:text/html;IEEE Xplore Full Text PDF:/Users/Hendrik/Zotero/storage/9X742YZK/Baltrušaitis et al. - 2019 - Multimodal Machine Learning A Survey and Taxonomy.pdf:application/pdf}
}

@inproceedings{karpathy_deep_2015,
    title = {Deep Visual-Semantic Alignments for Generating Image Descriptions},
    url = {https://www.cv-foundation.org/openaccess/content_cvpr_2015/html/Karpathy_Deep_Visual-Semantic_Alignments_2015_CVPR_paper.html},
    eventtitle = {Proceedings of the {IEEE} Conference on Computer Vision and Pattern Recognition},
    pages = {3128--3137},
    author = {Karpathy, Andrej and Fei-Fei, Li},
    urldate = {2021-03-30},
    date = {2015},
    file = {Full Text PDF:/Users/Hendrik/Zotero/storage/B48CM24P/Karpathy and Fei-Fei - 2015 - Deep Visual-Semantic Alignments for Generating Ima.pdf:application/pdf;Snapshot:/Users/Hendrik/Zotero/storage/JZ7JVFPQ/Karpathy_Deep_Visual-Semantic_Alignments_2015_CVPR_paper.html:text/html}
}

@article{kingma_auto-encoding_2014,
    title = {Auto-Encoding Variational Bayes},
    url = {http://arxiv.org/abs/1312.6114},
    abstract = {How can we perform efficient inference and learning in directed probabilistic models, in the presence of continuous latent variables with intractable posterior distributions, and large datasets? We introduce a stochastic variational inference and learning algorithm that scales to large datasets and, under some mild differentiability conditions, even works in the intractable case. Our contributions is two-fold. First, we show that a reparameterization of the variational lower bound yields a lower bound estimator that can be straightforwardly optimized using standard stochastic gradient methods. Second, we show that for i.i.d. datasets with continuous latent variables per datapoint, posterior inference can be made especially efficient by fitting an approximate inference model (also called a recognition model) to the intractable posterior using the proposed lower bound estimator. Theoretical advantages are reflected in experimental results.},
    journaltitle = {{arXiv}:1312.6114 [cs, stat]},
    author = {Kingma, Diederik P. and Welling, Max},
    urldate = {2021-03-30},
    date = {2014-05-01},
    eprinttype = {arxiv},
    eprint = {1312.6114},
    keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
    file = {arXiv Fulltext PDF:/Users/Hendrik/Zotero/storage/YN7CSDUJ/Kingma and Welling - 2014 - Auto-Encoding Variational Bayes.pdf:application/pdf;arXiv.org Snapshot:/Users/Hendrik/Zotero/storage/QX9BK2YR/1312.html:text/html}
}

@book{niculescu_convex_2018,
    location = {Cham},
    title = {Convex Functions and Their Applications},
    isbn = {978-3-319-78336-9 978-3-319-78337-6},
    url = {http://link.springer.com/10.1007/978-3-319-78337-6},
    series = {{CMS} Books in Mathematics},
    publisher = {Springer International Publishing},
    author = {Niculescu, Constantin P. and Persson, Lars-Erik},
    urldate = {2021-03-30},
    date = {2018},
    langid = {english},
    doi = {10.1007/978-3-319-78337-6},
    file = {Niculescu and Persson - 2018 - Convex Functions and Their Applications.pdf:/Users/Hendrik/Zotero/storage/PWHQL3RY/Niculescu and Persson - 2018 - Convex Functions and Their Applications.pdf:application/pdf}
}

@inproceedings{rezende_stochastic_2014,
    title = {Stochastic Backpropagation and Approximate Inference in Deep Generative Models},
    url = {http://proceedings.mlr.press/v32/rezende14.html},
    abstract = {We marry ideas from deep neural networks and approximate Bayesian inference to derive a generalised class of deep, directed generative models, endowed with a new algorithm for scalable inference an...},
    eventtitle = {International Conference on Machine Learning},
    pages = {1278--1286},
    booktitle = {International Conference on Machine Learning},
    publisher = {{PMLR}},
    author = {Rezende, Danilo Jimenez and Mohamed, Shakir and Wierstra, Daan},
    urldate = {2021-03-30},
    date = {2014-06-18},
    langid = {english},
    note = {{ISSN}: 1938-7228},
    file = {Full Text PDF:/Users/Hendrik/Zotero/storage/S55IPFPE/Rezende et al. - 2014 - Stochastic Backpropagation and Approximate Inferen.pdf:application/pdf;Snapshot:/Users/Hendrik/Zotero/storage/N6IMETCH/rezende14.html:text/html}
}

@article{shi_variational_2019,
    title = {Variational Mixture-of-Experts Autoencoders for Multi-Modal Deep Generative Models},
    url = {http://arxiv.org/abs/1911.03393},
    abstract = {Learning generative models that span multiple data modalities, such as vision and language, is often motivated by the desire to learn more useful, generalisable representations that faithfully capture common underlying factors between the modalities. In this work, we characterise successful learning of such models as the fulfillment of four criteria: i) implicit latent decomposition into shared and private subspaces, ii) coherent joint generation over all modalities, iii) coherent cross-generation across individual modalities, and iv) improved model learning for individual modalities through multi-modal integration. Here, we propose a mixture-of-experts multimodal variational autoencoder ({MMVAE}) to learn generative models on different sets of modalities, including a challenging image-language dataset, and demonstrate its ability to satisfy all four criteria, both qualitatively and quantitatively.},
    journaltitle = {{arXiv}:1911.03393 [cs, stat]},
    author = {Shi, Yuge and Siddharth, N. and Paige, Brooks and Torr, Philip H. S.},
    urldate = {2021-03-30},
    date = {2019-11-08},
    eprinttype = {arxiv},
    eprint = {1911.03393},
    keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
    file = {arXiv Fulltext PDF:/Users/Hendrik/Zotero/storage/RCT86RBU/Shi et al. - 2019 - Variational Mixture-of-Experts Autoencoders for Mu.pdf:application/pdf;arXiv.org Snapshot:/Users/Hendrik/Zotero/storage/LB9ZB8L7/1911.html:text/html}
}

@article{sutter_multimodal_2020,
    title = {Multimodal Generative Learning Utilizing Jensen-Shannon-Divergence},
    url = {http://arxiv.org/abs/2006.08242},
    abstract = {Learning from different data types is a long-standing goal in machine learning research, as multiple information sources co-occur when describing natural phenomena. However, existing generative models that approximate a multimodal {ELBO} rely on difficult or inefficient training schemes to learn a joint distribution and the dependencies between modalities. In this work, we propose a novel, efficient objective function that utilizes the Jensen-Shannon divergence for multiple distributions. It simultaneously approximates the unimodal and joint multimodal posteriors directly via a dynamic prior. In addition, we theoretically prove that the new multimodal {JS}-divergence ({mmJSD}) objective optimizes an {ELBO}. In extensive experiments, we demonstrate the advantage of the proposed {mmJSD} model compared to previous work in unsupervised, generative learning tasks.},
    journaltitle = {{arXiv}:2006.08242 [cs, stat]},
    author = {Sutter, Thomas M. and Daunhawer, Imant and Vogt, Julia E.},
    urldate = {2021-03-30},
    date = {2020-11-02},
    eprinttype = {arxiv},
    eprint = {2006.08242},
    keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
    file = {arXiv Fulltext PDF:/Users/Hendrik/Zotero/storage/2SGSPF93/Sutter et al. - 2020 - Multimodal Generative Learning Utilizing Jensen-Sh.pdf:application/pdf;arXiv.org Snapshot:/Users/Hendrik/Zotero/storage/4VI64PCH/2006.html:text/html}
}

@article{suzuki_joint_2016,
    title = {Joint Multimodal Learning with Deep Generative Models},
    url = {http://arxiv.org/abs/1611.01891},
    abstract = {We investigate deep generative models that can exchange multiple modalities bi-directionally, e.g., generating images from corresponding texts and vice versa. Recently, some studies handle multiple modalities on deep generative models, such as variational autoencoders ({VAEs}). However, these models typically assume that modalities are forced to have a conditioned relation, i.e., we can only generate modalities in one direction. To achieve our objective, we should extract a joint representation that captures high-level concepts among all modalities and through which we can exchange them bi-directionally. As described herein, we propose a joint multimodal variational autoencoder ({JMVAE}), in which all modalities are independently conditioned on joint representation. In other words, it models a joint distribution of modalities. Furthermore, to be able to generate missing modalities from the remaining modalities properly, we develop an additional method, {JMVAE}-kl, that is trained by reducing the divergence between {JMVAE}'s encoder and prepared networks of respective modalities. Our experiments show that our proposed method can obtain appropriate joint representation from multiple modalities and that it can generate and reconstruct them more properly than conventional {VAEs}. We further demonstrate that {JMVAE} can generate multiple modalities bi-directionally.},
    journaltitle = {{arXiv}:1611.01891 [cs, stat]},
    author = {Suzuki, Masahiro and Nakayama, Kotaro and Matsuo, Yutaka},
    urldate = {2021-03-30},
    date = {2016-11-06},
    eprinttype = {arxiv},
    eprint = {1611.01891},
    keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
    file = {arXiv Fulltext PDF:/Users/Hendrik/Zotero/storage/UZXUCHRL/Suzuki et al. - 2016 - Joint Multimodal Learning with Deep Generative Mod.pdf:application/pdf;arXiv.org Snapshot:/Users/Hendrik/Zotero/storage/2K9XPIJP/1611.html:text/html}
}

@inproceedings{tsai_learning_2018,
    title = {Learning Factorized Multimodal Representations},
    url = {https://openreview.net/forum?id=rygqqsA9KX},
    abstract = {We propose a model to learn factorized multimodal representations that are discriminative, generative, and interpretable.},
    eventtitle = {International Conference on Learning Representations},
    author = {Tsai, Yao-Hung Hubert and Liang, Paul Pu and Zadeh, Amir and Morency, Louis-Philippe and Salakhutdinov, Ruslan},
    urldate = {2021-03-30},
    date = {2018-09-27},
    langid = {english},
    file = {Full Text PDF:/Users/Hendrik/Zotero/storage/6A6KSPN4/Tsai et al. - 2018 - Learning Factorized Multimodal Representations.pdf:application/pdf;Snapshot:/Users/Hendrik/Zotero/storage/GDQUU3I9/forum.html:text/html}
}

@article{vedantam_generative_2018,
    title = {Generative Models of Visually Grounded Imagination},
    url = {http://arxiv.org/abs/1705.10762},
    abstract = {It is easy for people to imagine what a man with pink hair looks like, even if they have never seen such a person before. We call the ability to create images of novel semantic concepts visually grounded imagination. In this paper, we show how we can modify variational auto-encoders to perform this task. Our method uses a novel training objective, and a novel product-of-experts inference network, which can handle partially specified (abstract) concepts in a principled and efficient way. We also propose a set of easy-to-compute evaluation metrics that capture our intuitive notions of what it means to have good visual imagination, namely correctness, coverage, and compositionality (the 3 C's). Finally, we perform a detailed comparison of our method with two existing joint image-attribute {VAE} methods (the {JMVAE} method of Suzuki et.al. and the {BiVCCA} method of Wang et.al.) by applying them to two datasets: the {MNIST}-with-attributes dataset (which we introduce here), and the {CelebA} dataset.},
    journaltitle = {{arXiv}:1705.10762 [cs, stat]},
    author = {Vedantam, Ramakrishna and Fischer, Ian and Huang, Jonathan and Murphy, Kevin},
    urldate = {2021-03-30},
    date = {2018-11-09},
    eprinttype = {arxiv},
    eprint = {1705.10762},
    keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Statistics - Machine Learning},
    file = {arXiv Fulltext PDF:/Users/Hendrik/Zotero/storage/KB67TLNP/Vedantam et al. - 2018 - Generative Models of Visually Grounded Imagination.pdf:application/pdf;arXiv.org Snapshot:/Users/Hendrik/Zotero/storage/39Y5UK8T/1705.html:text/html}
}

@article{wu_multimodal_2018,
    title = {Multimodal Generative Models for Scalable Weakly-Supervised Learning},
    url = {http://arxiv.org/abs/1802.05335},
    abstract = {Multiple modalities often co-occur when describing natural phenomena. Learning a joint representation of these modalities should yield deeper and more useful representations. Previous generative approaches to multi-modal input either do not learn a joint distribution or require additional computation to handle missing data. Here, we introduce a multimodal variational autoencoder ({MVAE}) that uses a product-of-experts inference network and a sub-sampled training paradigm to solve the multi-modal inference problem. Notably, our model shares parameters to efficiently learn under any combination of missing modalities. We apply the {MVAE} on four datasets and match state-of-the-art performance using many fewer parameters. In addition, we show that the {MVAE} is directly applicable to weakly-supervised learning, and is robust to incomplete supervision. We then consider two case studies, one of learning image transformations---edge detection, colorization, segmentation---as a set of modalities, followed by one of machine translation between two languages. We find appealing results across this range of tasks.},
    journaltitle = {{arXiv}:1802.05335 [cs, stat]},
    author = {Wu, Mike and Goodman, Noah},
    urldate = {2021-03-30},
    date = {2018-11-12},
    eprinttype = {arxiv},
    eprint = {1802.05335},
    keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
    file = {arXiv Fulltext PDF:/Users/Hendrik/Zotero/storage/LVSFF454/Wu and Goodman - 2018 - Multimodal Generative Models for Scalable Weakly-S.pdf:application/pdf;arXiv.org Snapshot:/Users/Hendrik/Zotero/storage/48FDVEUH/1802.html:text/html}
}


@article{johnson_mimic-cxr-jpg_2019,
	title = {{MIMIC}-{CXR}-{JPG}, a large publicly available database of labeled chest radiographs},
	url = {http://arxiv.org/abs/1901.07042},
	abstract = {Chest radiography is an extremely powerful imaging modality, allowing for a detailed inspection of a patient's thorax, but requiring specialized training for proper interpretation. With the advent of high performance general purpose computer vision algorithms, the accurate automated analysis of chest radiographs is becoming increasingly of interest to researchers. However, a key challenge in the development of these techniques is the lack of sufficient data. Here we describe {MIMIC}-{CXR}-{JPG} v2.0.0, a large dataset of 377,110 chest x-rays associated with 227,827 imaging studies sourced from the Beth Israel Deaconess Medical Center between 2011 - 2016. Images are provided with 14 labels derived from two natural language processing tools applied to the corresponding free-text radiology reports. {MIMIC}-{CXR}-{JPG} is derived entirely from the {MIMIC}-{CXR} database, and aims to provide a convenient processed version of {MIMIC}-{CXR}, as well as to provide a standard reference for data splits and image labels. All images have been de-identified to protect patient privacy. The dataset is made freely available to facilitate and encourage a wide range of research in medical computer vision.},
	journaltitle = {{arXiv}:1901.07042 [cs, eess]},
	author = {Johnson, Alistair E. W. and Pollard, Tom J. and Greenbaum, Nathaniel R. and Lungren, Matthew P. and Deng, Chih-ying and Peng, Yifan and Lu, Zhiyong and Mark, Roger G. and Berkowitz, Seth J. and Horng, Steven},
	urldate = {2021-03-31},
	date = {2019-11-14},
	eprinttype = {arxiv},
	eprint = {1901.07042},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Electrical Engineering and Systems Science - Image and Video Processing},
	file = {arXiv Fulltext PDF:/Users/Hendrik/Zotero/storage/J6MBHIJ4/Johnson et al. - 2019 - MIMIC-CXR-JPG, a large publicly available database.pdf:application/pdf;arXiv.org Snapshot:/Users/Hendrik/Zotero/storage/TCH8K5K9/1901.html:text/html}
}

@book{bogachev2007measure,
  title={Measure theory},
  author={Bogachev, Vladimir I},
  volume={1},
  year={2007},
  publisher={Springer Science \& Business Media}
}


@inproceedings{huang_neural_2018,
	title = {Neural Autoregressive Flows},
	url = {http://proceedings.mlr.press/v80/huang18d.html},
	abstract = {Normalizing flows and autoregressive models have been successfully combined to produce state-of-the-art results in density estimation, via Masked Autoregressive Flows ({MAF}) (Papamakarios et al., 20...},
	eventtitle = {International Conference on Machine Learning},
	pages = {2078--2087},
	booktitle = {International Conference on Machine Learning},
	publisher = {{PMLR}},
	author = {Huang, Chin-Wei and Krueger, David and Lacoste, Alexandre and Courville, Aaron},
	urldate = {2021-04-01},
	date = {2018-07-03},
	langid = {english},
	note = {{ISSN}: 2640-3498},
	file = {Full Text PDF:/Users/Hendrik/Zotero/storage/XRY3BRP2/Huang et al. - 2018 - Neural Autoregressive Flows.pdf:application/pdf;Snapshot:/Users/Hendrik/Zotero/storage/2XQCARBD/huang18d.html:text/html}
}


@article{hochreiter_long_1997,
	title = {Long Short-Term Memory},
	volume = {9},
	issn = {0899-7667},
	url = {https://doi.org/10.1162/neco.1997.9.8.1735},
	doi = {10.1162/neco.1997.9.8.1735},
	abstract = {Learning to store information over extended time intervals by recurrent backpropagation takes a very long time, mostly because of insufficient, decaying error backflow. We briefly review Hochreiter's (1991) analysis of this problem, then address it by introducing a novel, efficient, gradient based method called long short-term memory ({LSTM}). Truncating the gradient where this does not do harm, {LSTM} can learn to bridge minimal time lags in excess of 1000 discrete-time steps by enforcing constant error flow through constant error carousels within special units. Multiplicative gate units learn to open and close access to the constant error flow. {LSTM} is local in space and time; its computational complexity per time step and weight is O. 1. Our experiments with artificial data involve local, distributed, real-valued, and noisy pattern representations. In comparisons with real-time recurrent learning, back propagation through time, recurrent cascade correlation, Elman nets, and neural sequence chunking, {LSTM} leads to many more successful runs, and learns much faster. {LSTM} also solves complex, artificial long-time-lag tasks that have never been solved by previous recurrent network algorithms.},
	pages = {1735--1780},
	number = {8},
	journaltitle = {Neural Computation},
	shortjournal = {Neural Computation},
	author = {Hochreiter, Sepp and Schmidhuber, Jürgen},
	urldate = {2021-04-01},
	date = {1997-11-15},
	file = {Full Text PDF:/Users/Hendrik/Zotero/storage/HCEHAKYR/Hochreiter and Schmidhuber - 1997 - Long Short-Term Memory.pdf:application/pdf;Snapshot:/Users/Hendrik/Zotero/storage/6USAAPTG/Long-Short-Term-Memory.html:text/html}
}


@article{dinh_nice_2015,
	title = {{NICE}: Non-linear Independent Components Estimation},
	url = {http://arxiv.org/abs/1410.8516},
	shorttitle = {{NICE}},
	abstract = {We propose a deep learning framework for modeling complex high-dimensional densities called Non-linear Independent Component Estimation ({NICE}). It is based on the idea that a good representation is one in which the data has a distribution that is easy to model. For this purpose, a non-linear deterministic transformation of the data is learned that maps it to a latent space so as to make the transformed data conform to a factorized distribution, i.e., resulting in independent latent variables. We parametrize this transformation so that computing the Jacobian determinant and inverse transform is trivial, yet we maintain the ability to learn complex non-linear transformations, via a composition of simple building blocks, each based on a deep neural network. The training criterion is simply the exact log-likelihood, which is tractable. Unbiased ancestral sampling is also easy. We show that this approach yields good generative models on four image datasets and can be used for inpainting.},
	journaltitle = {{arXiv}:1410.8516 [cs]},
	author = {Dinh, Laurent and Krueger, David and Bengio, Yoshua},
	urldate = {2021-04-01},
	date = {2015-04-10},
	eprinttype = {arxiv},
	eprint = {1410.8516},
	keywords = {Computer Science - Machine Learning},
	file = {arXiv Fulltext PDF:/Users/Hendrik/Zotero/storage/STEZXYWX/Dinh et al. - 2015 - NICE Non-linear Independent Components Estimation.pdf:application/pdf;arXiv.org Snapshot:/Users/Hendrik/Zotero/storage/A6T37WCB/1410.html:text/html}
}


@article{kingma_glow_2018,
	title = {Glow: Generative Flow with Invertible 1x1 Convolutions},
	url = {http://arxiv.org/abs/1807.03039},
	shorttitle = {Glow},
	abstract = {Flow-based generative models (Dinh et al., 2014) are conceptually attractive due to tractability of the exact log-likelihood, tractability of exact latent-variable inference, and parallelizability of both training and synthesis. In this paper we propose Glow, a simple type of generative flow using an invertible 1x1 convolution. Using our method we demonstrate a significant improvement in log-likelihood on standard benchmarks. Perhaps most strikingly, we demonstrate that a generative model optimized towards the plain log-likelihood objective is capable of efficient realistic-looking synthesis and manipulation of large images. The code for our model is available at https://github.com/openai/glow},
	journaltitle = {{arXiv}:1807.03039 [cs, stat]},
	author = {Kingma, Diederik P. and Dhariwal, Prafulla},
	urldate = {2021-04-01},
	date = {2018-07-10},
	eprinttype = {arxiv},
	eprint = {1807.03039},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Statistics - Machine Learning}
}


@inproceedings{prenger_waveglow_2019,
	title = {Waveglow: A Flow-based Generative Network for Speech Synthesis},
	doi = {10.1109/ICASSP.2019.8683143},
	shorttitle = {Waveglow},
	abstract = {In this paper we propose {WaveGlow}: a flow-based network capable of generating high quality speech from mel-spectrograms. {WaveGlow} combines insights from Glow [1] and {WaveNet} [2] in order to provide fast, efficient and high-quality audio synthesis, without the need for auto-regression. {WaveGlow} is implemented using only a single network, trained using only a single cost function: maximizing the likelihood of the training data, which makes the training procedure simple and stable. Our {PyTorch} implementation produces audio samples at a rate of more than 500 {kHz} on an {NVIDIA} V100 {GPU}. Mean Opinion Scores show that it delivers audio quality as good as the best publicly available {WaveNet} implementation. All code will be made publicly available online [3].},
	eventtitle = {{ICASSP} 2019 - 2019 {IEEE} International Conference on Acoustics, Speech and Signal Processing ({ICASSP})},
	pages = {3617--3621},
	booktitle = {{ICASSP} 2019 - 2019 {IEEE} International Conference on Acoustics, Speech and Signal Processing ({ICASSP})},
	author = {Prenger, R. and Valle, R. and Catanzaro, B.},
	date = {2019-05},
	note = {{ISSN}: 2379-190X},
	keywords = {Audio Synthesis, Deep Learning, Generative models, Text-to-speech},
	file = {IEEE Xplore Abstract Record:/Users/Hendrik/Zotero/storage/HDWS5R4T/8683143.html:text/html;IEEE Xplore Full Text PDF:/Users/Hendrik/Zotero/storage/3SGZ4BAC/Prenger et al. - 2019 - Waveglow A Flow-based Generative Network for Spee.pdf:application/pdf}
}


@inproceedings{ho_flow_2019,
	title = {Flow++: Improving Flow-Based Generative Models with Variational Dequantization and Architecture Design},
	url = {http://proceedings.mlr.press/v97/ho19a.html},
	shorttitle = {Flow++},
	abstract = {Flow-based generative models are powerful exact likelihood models with efficient sampling and inference. Despite their computational efficiency, flow-based models generally have much worse density ...},
	eventtitle = {International Conference on Machine Learning},
	pages = {2722--2730},
	booktitle = {International Conference on Machine Learning},
	publisher = {{PMLR}},
	author = {Ho, Jonathan and Chen, Xi and Srinivas, Aravind and Duan, Yan and Abbeel, Pieter},
	urldate = {2021-04-01},
	date = {2019-05-24},
	langid = {english},
	note = {{ISSN}: 2640-3498},
	file = {Full Text PDF:/Users/Hendrik/Zotero/storage/LQ3MUA3C/Ho et al. - 2019 - Flow++ Improving Flow-Based Generative Models wit.pdf:application/pdf;Snapshot:/Users/Hendrik/Zotero/storage/X94P6YD7/ho19a.html:text/html}
}


@inproceedings{behrmann_invertible_2019,
	title = {Invertible Residual Networks},
	url = {http://proceedings.mlr.press/v97/behrmann19a.html},
	abstract = {We show that standard {ResNet} architectures can be made invertible, allowing the same model to be used for classification, density estimation, and generation. Typically, enforcing invertibility requ...},
	eventtitle = {International Conference on Machine Learning},
	pages = {573--582},
	booktitle = {International Conference on Machine Learning},
	publisher = {{PMLR}},
	author = {Behrmann, Jens and Grathwohl, Will and Chen, Ricky T. Q. and Duvenaud, David and Jacobsen, Joern-Henrik},
	urldate = {2021-04-02},
	date = {2019-05-24},
	langid = {english},
	note = {{ISSN}: 2640-3498},
	file = {Full Text PDF:/Users/Hendrik/Zotero/storage/4MI5NR64/Behrmann et al. - 2019 - Invertible Residual Networks.pdf:application/pdf;Snapshot:/Users/Hendrik/Zotero/storage/CNUKZKKM/behrmann19a.html:text/html}
}


@article{chen_residual_2020,
	title = {Residual Flows for Invertible Generative Modeling},
	url = {http://arxiv.org/abs/1906.02735},
	abstract = {Flow-based generative models parameterize probability distributions through an invertible transformation and can be trained by maximum likelihood. Invertible residual networks provide a flexible family of transformations where only Lipschitz conditions rather than strict architectural constraints are needed for enforcing invertibility. However, prior work trained invertible residual networks for density estimation by relying on biased log-density estimates whose bias increased with the network's expressiveness. We give a tractable unbiased estimate of the log density using a "Russian roulette" estimator, and reduce the memory required during training by using an alternative infinite series for the gradient. Furthermore, we improve invertible residual blocks by proposing the use of activation functions that avoid derivative saturation and generalizing the Lipschitz condition to induced mixed norms. The resulting approach, called Residual Flows, achieves state-of-the-art performance on density estimation amongst flow-based models, and outperforms networks that use coupling blocks at joint generative and discriminative modeling.},
	journaltitle = {{arXiv}:1906.02735 [cs, stat]},
	author = {Chen, Ricky T. Q. and Behrmann, Jens and Duvenaud, David and Jacobsen, Jörn-Henrik},
	urldate = {2021-04-02},
	date = {2020-07-23},
	eprinttype = {arxiv},
	eprint = {1906.02735},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {arXiv Fulltext PDF:/Users/Hendrik/Zotero/storage/UDQ2Q5YG/Chen et al. - 2020 - Residual Flows for Invertible Generative Modeling.pdf:application/pdf}
}


@article{berg_sylvester_2019,
	title = {Sylvester Normalizing Flows for Variational Inference},
	url = {http://arxiv.org/abs/1803.05649},
	abstract = {Variational inference relies on flexible approximate posterior distributions. Normalizing flows provide a general recipe to construct flexible variational posteriors. We introduce Sylvester normalizing flows, which can be seen as a generalization of planar flows. Sylvester normalizing flows remove the well-known single-unit bottleneck from planar flows, making a single transformation much more flexible. We compare the performance of Sylvester normalizing flows against planar flows and inverse autoregressive flows and demonstrate that they compare favorably on several datasets.},
	journaltitle = {{arXiv}:1803.05649 [cs, stat]},
	author = {Berg, Rianne van den and Hasenclever, Leonard and Tomczak, Jakub M. and Welling, Max},
	urldate = {2021-04-02},
	date = {2019-02-20},
	eprinttype = {arxiv},
	eprint = {1803.05649},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Statistics - Machine Learning, Statistics - Methodology},
	file = {arXiv Fulltext PDF:/Users/Hendrik/Zotero/storage/8QMQLHTS/Berg et al. - 2019 - Sylvester Normalizing Flows for Variational Infere.pdf:application/pdf;arXiv.org Snapshot:/Users/Hendrik/Zotero/storage/9WA6H4TB/1803.html:text/html}
}


@inproceedings{sutter_generalized_2020,
	title = {Generalized Multimodal {ELBO}},
	url = {https://openreview.net/forum?id=5Y21V0RDBV},
	abstract = {Multiple data types naturally co-occur when describing real-world phenomena and learning from them is a long-standing goal in machine learning research. However, existing self-supervised generative...},
	eventtitle = {International Conference on Learning Representations},
	author = {Sutter, Thomas Marco and Daunhawer, Imant and Vogt, Julia E.},
	urldate = {2021-04-02},
	date = {2020-09-28},
	langid = {english},
	file = {Full Text PDF:/Users/Hendrik/Zotero/storage/I754DQ4N/Sutter et al. - 2020 - Generalized Multimodal ELBO.pdf:application/pdf;Snapshot:/Users/Hendrik/Zotero/storage/93R3JL2U/forum.html:text/html}
}